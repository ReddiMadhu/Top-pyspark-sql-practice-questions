{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4535f70a-fbc0-4ff1-b698-f1bc1054b4c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "[Question 1](https://datalemur.com/questions/trade-in-payouts) [Question 2](https://datalemur.com/questions/follow-up-airpod-percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8151a965-39cd-4851-8725-9c96c137ca95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DateType,TimestampType\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1f61599b-c64f-4404-a786-a0fa10e46752",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Schema for trade_in_transactions\n",
    "transactions_schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"model_id\", IntegerType(), True),\n",
    "    StructField(\"store_id\", IntegerType(), True),\n",
    "    StructField(\"transaction_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "# Sample data (convert string date to datetime.date)\n",
    "transactions_data = [\n",
    "    (1, 112, 512, datetime.strptime(\"01/01/2022\", \"%d/%m/%Y\").date()),\n",
    "    (2, 113, 512, datetime.strptime(\"01/01/2022\", \"%d/%m/%Y\").date())\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_transactions = spark.createDataFrame(transactions_data, schema=transactions_schema)\n",
    "df_transactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d7bce78-4262-4a9e-9f28-4f3fa1b489a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Schema for trade_in_payouts\n",
    "payouts_schema = StructType([\n",
    "    StructField(\"model_id\", IntegerType(), True),\n",
    "    StructField(\"model_name\", StringType(), True),\n",
    "    StructField(\"payout_amount\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "payouts_data = [\n",
    "    (111, \"iPhone 11\", 200),\n",
    "    (112, \"iPhone 12\", 350),\n",
    "    (113, \"iPhone 13\", 450),\n",
    "    (114, \"iPhone 13 Pro Max\", 650)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_payouts = spark.createDataFrame(payouts_data, schema=payouts_schema)\n",
    "df_payouts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acfbcd97-98bc-40b2-8d3e-59c03eab2866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as _sum\n",
    "\n",
    "df_joined = df_transactions.join(\n",
    "    df_payouts,\n",
    "    df_transactions[\"model_id\"] == df_payouts[\"model_id\"],\n",
    "    \"inner\"\n",
    ").groupBy(df_transactions[\"store_id\"]).agg(\n",
    "    _sum(df_payouts[\"payout_amount\"]).alias(\"total_payout\")\n",
    ").orderBy(\"total_payout\", ascending=False)\n",
    "\n",
    "display(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8df480c-c140-49d9-8332-e147b63f6ba8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Register the DataFrame as a SQL temporary view\n",
    "df_transactions.createOrReplaceTempView(\"trade_in_transactions\")\n",
    "df_payouts.createOrReplaceTempView(\"trade_in_payouts\")\n",
    "\n",
    "# SQL query\n",
    "sql_query = \"\"\"\n",
    "SELECT \n",
    "  transactions.store_id, \n",
    "  SUM(payouts.payout_amount) AS total_payout\n",
    "FROM trade_in_transactions AS transactions\n",
    "INNER JOIN trade_in_payouts AS payouts\n",
    "  ON transactions.model_id = payouts.model_id\n",
    "GROUP BY transactions.store_id\n",
    "ORDER BY total_payout DESC\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "df_result = spark.sql(sql_query)\n",
    "\n",
    "# Display the result\n",
    "display(df_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "62bfe165-6059-4a08-9ed7-4162202db276",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "807bc705-7769-42e8-b53e-4df8bd7f40ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define schema for transactions\n",
    "transactions_schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"product_name\", StringType(), True),\n",
    "    StructField(\"transaction_timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "# Define sample data (convert string to datetime)\n",
    "transactions_data = [\n",
    "    (1, 101, \"iPhone\", datetime.strptime(\"08/08/2022 00:00:00\", \"%d/%m/%Y %H:%M:%S\")),\n",
    "    (2, 101, \"AirPods\", datetime.strptime(\"08/08/2022 00:00:00\", \"%d/%m/%Y %H:%M:%S\")),\n",
    "    (5, 301, \"iPhone\", datetime.strptime(\"09/05/2022 00:00:00\", \"%d/%m/%Y %H:%M:%S\")),\n",
    "    (6, 301, \"iPad\", datetime.strptime(\"09/06/2022 00:00:00\", \"%d/%m/%Y %H:%M:%S\")),\n",
    "    (7, 301, \"AirPods\", datetime.strptime(\"09/07/2022 00:00:00\", \"%d/%m/%Y %H:%M:%S\"))\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df_transactions = spark.createDataFrame(transactions_data, schema=transactions_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e47fca07-a5db-48fb-87d4-4a93edfe8974",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_transactions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57f65d1b-739b-447d-b111-47a24f24b541",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "w = Window.partitionBy(df_transactions[\"customer_id\"]).orderBy(df_transactions[\"transaction_id\"])\n",
    "df = df_transactions.withColumn(\n",
    "    \"previous\", \n",
    "    lead(df_transactions[\"product_name\"]).over(w)\n",
    ").withColumn(\n",
    "    \"count\", \n",
    "    when((df_transactions[\"product_name\"] == \"iPhone\") & (col(\"previous\") == \"AirPods\"), 1).otherwise(0)\n",
    ")\n",
    "total_customers = df.select(\"customer_id\").distinct().count()\n",
    "\n",
    "# Calculate the sum of 'count' column\n",
    "sum_count = df.agg(sum(\"count\")).collect()[0][0]\n",
    "\n",
    "result = (sum_count / total_customers)*100\n",
    "print(result)\n",
    "\n",
    "# Display the DataFrame and the result"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "01_TradeInPayouts_and_Airpod_FollowUp_2025-08-06",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
